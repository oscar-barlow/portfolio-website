---
layout: post
title: "Machine learning ethics at a high level"
date: 2024-04-18
---
Machine learning ethics should be considered separately from data ethics. This post sets out high level categories for the former, whereas the latter comprises things like retention periods and rights to amend incorrect personal data, and so on. There's an obvious relationship between the two but they are nonetheless distinct. Also separate are considerations related to developing [artificial general intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence). This is also clearly related, but a significant and characteristically different enough topic to warant separate consideration.

---

## Purpose
The end to which machine learning is put is an ethical matter - for, building machine learning systems for military effectiveness, or to help with weapons research in the same way that some models are used for bioscience research. It will be difficult to disentangle this from the purpose of the organisation as a whole, although not always. For example, a machine learning model that deliberately automates [redlining](https://www.law.cornell.edu/wex/redlining) is unethical, but a financial institution offering mortgages is not inherently unethical.

## Fairness
In machine learning fairness often means with respect to racial prejudice. This is clearly important. At a more abstract level, this suggests questions about whether some demographics are treated worse by a machine learning systems simply on the basis of belonging to that demographic, as for example with [policing and sentencing algorithms](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/). As shown in the previous example, there is a link to the data on which models are trained.

As well as informing decisions, there's the matter of access to services. Although this example is several years old at the time of writing, there is the example of [voice recognition assistants working worse with women's voices](https://www.theregister.com/2018/03/14/voice_recognition_systems_are_naturally_sexist/).

## Explainability
This is a somewhat more procedural question. When a recommendation is made by a machine learning system, or an automated decision taken, that this behaviour can be satisfactorily explained. Indeed this is a [right provided by the EU AI Act](https://datacentrereview.com/2023/10/the-need-for-transparency-and-explainability-in-eu-ai-regulation/).

Linked article mentions reliability - accountability more important.

## Manipulation
The social and political sphere, and advertising

## Privacy and civil liberties
Facial recognition 

---

How can we avoid the medical ethics trap?